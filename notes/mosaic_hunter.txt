Mosaic Hunter

Environment Setup:

    MosaicHunter
    #Append mosaic hunter jar file path to MH variable
        MH=/mnt/data/jeremy/programs/MosaicHunter/build/mosaichunter.jar
        #Use $MH when calling mosaic hunter

    Blat
        module add blat/35x1

    Java (>= 1.7)
    #Default = 1.7

    Perl
    #Default = 5.10.1

    GATK Suite
    module add GATK/3.5-0 samtools/1.3.1 samblaster/0.1.22 sambamba/0.6.1 bwa/0.7.15 tabix_bgzip/1.3.1

    CNVnator
    module add cnvnator/0.3.2 ROOT/6.04
    
    XHMM
    module add xhmm/1.0 bedops/2.4.26

Workflow:

    Input requirements:
        Idexed reference genome (.fa & .fai)
        Pre-processed sample BAMs (aligned, sorted, indexed,  marked duplicates, GATK IndelRealignment & BaseRecalibration)

1. Prepare reads
    #Accepts WGS & WES
    #Remove improperly mapped reads (keep proper-mapped reads)
    samtools view -h -f 0x2 input.bam | perl -ne 'print if (/^@/||(/NM:i:(\d+)/&&$1<=4))' | samtools view -Sb - >cleaner.bam

2. Prepare sample-specific files
    a. Call InDels w/ GATK
        i.WGS
            #Make config file
            python3 /mnt/data/jeremy/scripts/GATK_WGS/make_unit_config.py --fastq PATH/TO/FASTQS/*R1.fastq.gz --config PATH/TO/PROCESSING/DIRECTORY/ID_gatk.json GATK $GATK \
            /mnt/data/jeremy/scripts/GATK_WGS/rm_rep.py
    
            #Run GATK snakemake
            snakemake -w 60 --configfile PATH/TO/CONFIG_FILE/ID_gatk.json -p -j 30 --nocolor --verbose -s /mnt/data/jeremy/scripts/GATK_WGS/gatk_call_recal_vars.smk \
            --cluster "sbatch -N 1 -n 1 -c {threads} --error Logs/gatk_{rule}_%j.log --output Logs/gatk_{rule}_%j.log"            

        ii.WES
            #Make config file    
            python3 /mnt/data/jeremy/scripts/GATK_WES/make_unit_config.py --fastq PATH/TO/FASTQS/*R1.fastq.gz --config PATH/TO/PROCESSING/DIRECTORY/ID_gatk.json GATK $GATK \
            /mnt/data/jeremy/scripts/GATK_WES/rm_rep.py

            #Run GATK snakemake
            snakemake -w 60 --configfile PATH/TO/CONFIG_FILE/ID_gatk.json -p -j 30 --nocolor --verbose -s /mnt/data/jeremy/scripts/GATK_WES/gatk_wes_call_recal_vars.smk \
            --cluster "sbatch -N 1 -n 1 -c {threads} --error Logs/gatk_{rule}_%j.log --output Logs/gatk_{rule}_%j.log"

    b. Call CNVs    
        i. WGS -> CNVnator
            #Extracting read mapping from BAM/SAM files
            cnvnator -root {sample}.root -tree sample.bam
    
            #Generate histogram
            cnvnator -root {sample}.root -his bin_size -d /running/directory

            #Calculate statistics
            cnvnator -root {sample}.root -stat bin_size

            #RD signal partitioning
            cnvnator -root {sample}.root -partition bin_size

            #CNV calling
            cnvnator -root {sample}.root -call bin_size > {sample}_cnv_calls                     
        
            #Genotyping
                #Recommend sorting list of regions by chromosomes
            cnvnator -root {sample}.root -genotype bin_size

        ii. WES -> xhmm
            #Input: "analysis-ready" BAM files
            Add locations of per-sample BAM files into file -> group1.READS.bam.list
            #GATK DepthOfCoverage
                #Obtain sequencing depth information
            java -Xmx3072m -jar $GATK -T DepthOfCoverage -I group1.READS.bam.list \
            -L /mnt/data/jeremy/scripts/XHMM/refs/converted_to_grch37_format/S04380110_Padded_grch37.bed -R /mnt/data/reference/hs37d5.fa \
            -dt BY_SAMPLE -dcov 5000 -l INFO --omitDepthOutputAtEachBase -omitLocusTable --minBaseQuality 0 --minMappingQuality 20 \
            --start 1 --stop 5000 --nBins 200 --includeRefNSites --countType COUNT_FRAGMENTS -o group1.DATA 

            #Combine GATK DepthOfCoverage outputs
                #ONLY if using multiple grouped BAM files (group1.READS.bam.list, group2.READS.bam.list, etc.)
            xhmm --mergeGATKdepths -o DATA.RD.txt --GATKdepths group1.DATA.sample_interval_summary \
            --GATKdepths group2.DATA.sample_interval_summary

            #GATK calculate GC content of targets
            java -Xmx3072m -jar $GATK -T GCContentByInterval -L /mnt/data/jeremy/scripts/XHMM/refs/converted_to_grch37_format/S04380110_Padded_grch37.bed \
            -R /mnt/data/reference/hs37d5.fa -o /PATH/TO/OUTPUT/DIRECTORY/gatk_gc_content/DATA.locus_GC.txt

            #4 optional steps to calculate the fraction of repeat-masked bases
                #Wasn't helpful running example (PWS10) sample so may be excluded
            
            #Filter samples and targets and prepare for normalization
            xhmm --matrix -r DATA.RD.txt --centerData --centerType target -o DATA.filtered_centered.RD.txt \
            --outputExcludedTargets DATA.filtered_centered.RD.txt.filtered_targets.txt \
            --outputExcludedSamples DATA.filtered_centered.RD.txt.filtered_samples.txt \
            --excludeTargets DATA_extreme_gc_targets.txt --minTargetSize 10 --maxTargetSize 10000 \
            --minMeanTargetRD 10 --maxMeanTargetRD 500 --minMeanSampleRD 25 --max MeanSampleRD 200 --maxSdSampleRD 150

            #PCA on mean-centered data
            xhmm --matrix -r DATA.PCA_normalized.txt --centerData \
            --centerType sample --zScoreData -o DATA.PCA_normalized.filtered.sample_zscores.RD.txt \
            --outputExcludedTargets DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_targets.txt \
            --outputExcludedSamples DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_samples.txt --maxSdTargetRD 30 

            #Normalize mean-centered data using PCA
            xhmm --normalize -r DATA.filtered_centered.RD.txt --PCAfiles DATA.RD_PCA --normalizeOutput DATA.PCA_normalized.txt \
            --PCnormalizeMethod PVE_mean --PVE_mean_factor 0.7 

            #Filter and calculate z-scores for data
            xhmm --matrix -r DATA.PCA_normalized.txt --centerData --centerType sample --zScoreData \
            -o DATA.PCA_normalized.filtered.sample_zscores.RD.txt --outputExcludedTargets DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_targets.txt \
            --outputExcludedSamples DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_samples.txt --maxSdTargetRD 30

            #Restrict to same samples and targets as filtered, normalized data
            xhmm --matrix -r DATA.RD.txt --excludeTargets DATA.filtered_centered.RD.txt.filtered_targets.txt \
            --excludeTargets DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_targets.txt \
            --excludeSamples DATA.filtered_centered.RD.txt.filtered_samples.txt \
            --excludeSamples DATA.PCA_normalized.filtered.sample_zscores.RD.txt.filtered_samples.txt -o DATA.same_filtered.RD.txt            

            #Call CNVs (FINALLY!)
            xhmm --discover -p params.txt -r DATA.PCA_normalized.filtered.sample_zscores.RD.txt \
            -R DATA.same_filtered.RD.txt -c DATA.xcnv -a DATA.aux_xcnv -s DATA

            #Genotype
            xhmm --genotype -p /cm/shared/plab/apps/xhmm/1.0/params.txt -r DATA.PCA_normalized.filtered.sample_zscores.RD.txt \
            -R DATA.same_filtered.RD.txt -g DATA.xcnv -F human_g1k_v37.fasta -v DATA.vcf 

3. Merge InDels & CNV regions & convert to BED



4. Run MosaicHunter
    cd your_path/MosaicHunter/
    
    java -jar $MH genome \
    -P input_file=demo/demo_sample.bam \
    -P reference_file=demo/hg37_chr18.fa \
    -P mosaic_filter.sex=M \
    -P mosaic_filter.dbsnp_file=demo/dbsnp137_hg37_chr18_demo.tsv \
    -P repetitive_region_filter.bed_file=resources/all_repeats.b37.bed \
    -P indel_region_filter.bed_file=demo/demo_sample.indel_CNV.bed \
    -P common_site_filter.bed_file=resources/WGS.error_prone.b37.bed \
    -P output_dir=demo_output
 




